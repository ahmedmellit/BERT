{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4ab5fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6766435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nitialize our model and tokenizer:\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "###Tokenize the sentences like before:\n",
    "sent = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "175e1e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionary: stores tokenized sentences\n",
    "token = {'input_ids': [], 'attention_mask': []}\n",
    "for sentence in sent:\n",
    "    # encode each sentence, append to dictionary\n",
    "    new_token = tokenizer.encode_plus(sentence, max_length=128,\n",
    "                                       truncation=True, padding='max_length',\n",
    "                                       return_tensors='pt')\n",
    "    token['input_ids'].append(new_token['input_ids'][0])\n",
    "    token['attention_mask'].append(new_token['attention_mask'][0])\n",
    "# reformat list of tensors to single tensor\n",
    "token['input_ids'] = torch.stack(token['input_ids'])\n",
    "token['attention_mask'] = torch.stack(token['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "433f74b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Process tokens through model:\n",
    "output = model(**token)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c92c18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0692,  0.6230,  0.0354,  ...,  0.8033,  1.6314,  0.3281],\n",
       "         [ 0.0367,  0.6842,  0.1946,  ...,  0.0848,  1.4747, -0.3008],\n",
       "         [-0.0121,  0.6543, -0.0727,  ..., -0.0326,  1.7717, -0.6812],\n",
       "         ...,\n",
       "         [ 0.1953,  1.1085,  0.3390,  ...,  1.2826,  1.0114, -0.0728],\n",
       "         [ 0.0902,  1.0288,  0.3297,  ...,  1.2940,  0.9865, -0.1113],\n",
       "         [ 0.1240,  0.9737,  0.3933,  ...,  1.1359,  0.8768, -0.1043]],\n",
       "\n",
       "        [[-0.3212,  0.8251,  1.0554,  ..., -0.1855,  0.1517,  0.3937],\n",
       "         [-0.7146,  1.0297,  1.1217,  ...,  0.0331,  0.2382, -0.1563],\n",
       "         [-0.2352,  1.1353,  0.8594,  ..., -0.4310, -0.0272, -0.2968],\n",
       "         ...,\n",
       "         [-0.5400,  0.3236,  0.7839,  ...,  0.0022, -0.2994,  0.2659],\n",
       "         [-0.5643,  0.3187,  0.9576,  ...,  0.0342, -0.3030,  0.1878],\n",
       "         [-0.5172,  0.3599,  0.9336,  ...,  0.0243, -0.2232,  0.1672]],\n",
       "\n",
       "        [[-0.7576,  0.8399, -0.3792,  ...,  0.1271,  1.2514,  0.1365],\n",
       "         [-0.6591,  0.7613, -0.4662,  ...,  0.2259,  1.1289, -0.3611],\n",
       "         [-0.9007,  0.6791, -0.3778,  ...,  0.1142,  0.9080, -0.1830],\n",
       "         ...,\n",
       "         [-0.2158,  0.5463,  0.3117,  ...,  0.1802,  0.7169, -0.0672],\n",
       "         [-0.3092,  0.4833,  0.3021,  ...,  0.2289,  0.6656, -0.0932],\n",
       "         [-0.2940,  0.4678,  0.3095,  ...,  0.2782,  0.5144, -0.1021]],\n",
       "\n",
       "        [[-0.2362,  0.8551, -0.8040,  ...,  0.6122,  0.3003, -0.1492],\n",
       "         [-0.0868,  0.9531, -0.6419,  ...,  0.7867,  0.2960, -0.7350],\n",
       "         [-0.3016,  1.0148, -0.3380,  ...,  0.8634,  0.0463, -0.3623],\n",
       "         ...,\n",
       "         [-0.1090,  0.6320, -0.8433,  ...,  0.7485,  0.1025,  0.0149],\n",
       "         [ 0.0072,  0.7347, -0.7689,  ...,  0.6064,  0.1287,  0.0331],\n",
       "         [-0.1108,  0.7605, -0.4447,  ...,  0.6719,  0.1059, -0.0034]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dense vector representations of text are contained within the outputs 'last_hidden_state' tensor\n",
    "embeddings = output.last_hidden_state\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfc1122b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To perform this operation, we first resize our attention_mask tensor:\n",
    "att_mask = token['attention_mask']\n",
    "att_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7da01d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = att_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa47f8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_embeddings = embeddings * mask\n",
    "mask_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7af0678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then we sum the remained of the embeddings along axis 1:\n",
    "summed = torch.sum(mask_embeddings, 1)\n",
    "summed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6442d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then sum the number of values that must be given attention in each position of the tensor:\n",
    "summed_mask = torch.clamp(mask.sum(1), min=1e-9)\n",
    "summed_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9276f638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0745,  0.8637,  0.1795,  ...,  0.7734,  1.7247, -0.1803],\n",
       "        [-0.3715,  0.9729,  1.0840,  ..., -0.2552, -0.2759,  0.0358],\n",
       "        [-0.5030,  0.7950, -0.1240,  ...,  0.1441,  0.9704, -0.1791],\n",
       "        [-0.2131,  1.0175, -0.8833,  ...,  0.7371,  0.1947, -0.3011]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pooled = summed / summed_mask\n",
    "mean_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e415c00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33088917, 0.72192585, 0.55483645]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#Let's calculate cosine similarity for sentence 0:\n",
    "# convert from PyTorch tensor to numpy array\n",
    "mean_pooled = mean_pooled.detach().numpy()\n",
    "# calculate\n",
    "cosine_similarity(\n",
    "    [mean_pooled[0]],\n",
    "    mean_pooled[1:]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
